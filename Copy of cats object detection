{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1k5jIhYaig4qDudjO621wCZySJND4DpH7","timestamp":1751462928604}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"imfQnA2KPh5P"},"outputs":[],"source":["import xml.etree.ElementTree as ET\n","import os\n","import tensorflow as tf\n","def parse_voc_annotations(annotation_dir, image_dir, class_map):\n","    image_paths = []\n","    bbox_data =[]\n","    class_labels =[]\n","    for xml_file in sorted(os.listdir(annotation_dir)):\n","        if not xml_file.endswith(\".xml\"):\n","            continue\n","        tree = ET.parse(os.path.join(annotation_dir,xml_file))\n","        root= tree.getroot()\n","        image_file_name = root.find(\"filename\").text\n","        path = os.path.join(image_dir,image_file_name)\n","\n","        size = root.find(\"size\")\n","        img_width = int(size.find(\"width\").text)\n","        img_height = int(size.find(\"height\").text)\n","\n","        obj = root.find(\"object\")\n","        if obj is not None:\n","            class_name = obj.find(\"name\").text\n","            if class_name not in class_map:\n","                continue\n","            class_id = class_map[class_name]\n","\n","            bndbox = obj.find(\"bndbox\")\n","            xmin = float(bndbox.find(\"xmin\").text) / img_width\n","            ymin = float(bndbox.find(\"ymin\").text) / img_height\n","            xmax = float(bndbox.find(\"xmax\").text) / img_width\n","            ymax = float(bndbox.find(\"ymax\").text) / img_height\n","            image_paths.append(path)\n","            bbox_data.append([xmin, ymin, xmax, ymax])\n","            class_labels.append(class_id)\n","    return image_paths, bbox_data, class_labels\n"]},{"cell_type":"code","source":["image_dir = \"data/images/\"\n","annotation_dir = \"data/Annotations/\"\n","class_map = {\"Cat\": 0, \"Dog\": 1}\n","\n","image_paths, bbox_data, class_labels = parse_voc_annotations(\n","    annotation_dir=annotation_dir,\n","    image_dir=image_dir,\n","    class_map=class_map\n",")"],"metadata":{"id":"T59-XoyiPpax"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_paths = tf.constant(image_paths)\n","bbox_data = tf.constant(bbox_data, dtype=tf.float32)\n","class_labels = tf.constant(class_labels, dtype=tf.int32)\n","\n","def load_and_preprocess_image(path, bbox, label):\n","    image = tf.io.read_file(path)\n","    image = tf.image.decode_image(image, channels=3)\n","    image.set_shape([None, None, 3])\n","    image = tf.image.resize(image, [128, 128])\n","    image = image / 255.0\n","    return image, {\"class_output\": label, \"box_output\": bbox}\n","\n","\n","dataset = tf.data.Dataset.from_tensor_slices((image_paths, bbox_data, class_labels))\n","dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","\n","dataset = dataset.shuffle(buffer_size=1024).batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","DATASET_SIZE = len(image_paths)\n","train_size = int(0.8 * DATASET_SIZE)\n","\n","train_ds = dataset.take(train_size)\n","val_ds = dataset.skip(train_size)"],"metadata":{"id":"Tb5Zz3TTPsC5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","\n","base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n","base_model.trainable = False\n","\n","inputs = Input(shape=(128, 128, 3))\n","x = base_model(inputs, training=False)\n","x = GlobalAveragePooling2D()(x)\n","\n","box_output = Dense(4, activation='sigmoid', name='box_output')(x)\n","\n","class_output = Dense(len(class_map), activation='softmax', name='class_output')(x)\n","\n","model = Model(inputs=inputs, outputs=[class_output, box_output])\n","\n","\n","model.compile(optimizer='adam',\n","              loss={\n","                  'class_output': 'sparse_categorical_crossentropy',\n","                  'box_output': 'mae'\n","              },\n","              metrics={\n","                  'class_output': 'accuracy',\n","                  'box_output': 'mae'\n","              })\n","\n","model.summary()"],"metadata":{"id":"iBF6dNYZPxUW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","history = model.fit(train_ds,\n","                    epochs=10,\n","                    validation_data=val_ds,\n","                    callbacks =[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True, mode=\"max\"),\n","                                tf.keras.callbacks.ModelCheckpoint(\"bestmodel.keras\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=1)],\n","                    verbose=1\n","                    )\n"],"metadata":{"id":"7PwLCsIwP2r0"},"execution_count":null,"outputs":[]}]}